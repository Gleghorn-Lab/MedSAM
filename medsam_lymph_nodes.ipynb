{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 0:\n",
    "!pip install -r requirements.txt -U\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Authentication\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import huggingface_hub\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "from utils.demo import BboxPromptDemo\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "hf_token = input(\"Enter your Hugging Face token: \")\n",
    "huggingface_hub.login(token=hf_token)\n",
    "\n",
    "print(\"Authentication successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cfe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Dataset and Model (From Hugging Face)\n",
    "\n",
    "print(\"Loading lymph node dataset...\")\n",
    "dataset_input = input(\"Please enter dataset path: \")\n",
    "\n",
    "try:\n",
    "    # First, analyze the dataset structure\n",
    "    temp_dataset = load_dataset(dataset_input, token=True)\n",
    "    \n",
    "    print(\"ðŸ” Dataset Analysis:\")\n",
    "    print(f\"Available splits: {list(temp_dataset.keys())}\")\n",
    "    for split_name in temp_dataset.keys():\n",
    "        print(f\"  - {split_name}: {len(temp_dataset[split_name])} items\")\n",
    "        if len(temp_dataset[split_name]) > 0:\n",
    "            print(f\"    Features: {temp_dataset[split_name].features}\")\n",
    "    \n",
    "    # Choose which split to use as 'train'\n",
    "    chosen_split = input(f\"Which split to use as 'train'? {list(temp_dataset.keys())}: \")\n",
    "    \n",
    "    if chosen_split in temp_dataset:\n",
    "        print(f\"Will use '{chosen_split}' split\")\n",
    "        \n",
    "        # Load the chosen split and create 'train' alias\n",
    "        image_dataset = temp_dataset\n",
    "        image_dataset['train'] = image_dataset[chosen_split]\n",
    "        \n",
    "        print(\"Dataset info:\")\n",
    "        print(f\"Available splits: {list(image_dataset.keys())}\")\n",
    "        print(f\"Number of train images: {len(image_dataset['train'])}\")\n",
    "        print(f\"Features: {image_dataset['train'].features}\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\" Split '{chosen_split}' not found in dataset\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"\\n Troubleshooting:\")\n",
    "    print(\"1. Check if the dataset repository exists and is accessible\")\n",
    "    print(\"2. Verify your HuggingFace token has the correct permissions\")\n",
    "    print(\"3. Make sure the dataset path is correct\")\n",
    "    print(\"4. Try a different split name if available\")\n",
    "    print(\"\\n Cannot continue without valid dataset. Please fix the issue and try again.\")\n",
    "    raise  # Re-raise the error to stop execution\n",
    "\n",
    "# Load MedSAM model from Hugging Face\n",
    "print(\"\\nLoading MedSAM model from Hugging Face...\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "try:\n",
    "    # Use your manually downloaded checkpoint if already downloaded\n",
    "    MedSAM_CKPT_PATH = \"/home/medsam-vit-b/medsam_vit_b.pth\"\n",
    "    \n",
    "    # #OR USE THIS section to download the model directly from Hugging Face into cache\n",
    "    # MedSAM_CKPT_PATH = hf_hub_download(\n",
    "    #     repo_id=\"GleghornLab/medsam-vit-b\",\n",
    "    #     filename=\"medsam_vit_b.pth\",\n",
    "    #     token=True\n",
    "    # )\n",
    "    \n",
    "    print(f\"Model downloaded to: {MedSAM_CKPT_PATH}\")\n",
    "    \n",
    "    # Load the model\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "    medsam_model = medsam_model.to(device)\n",
    "    medsam_model.eval()\n",
    "    \n",
    "    print(f\"MedSAM model loaded successfully on {device}\")\n",
    "    \n",
    "    # Show device info\n",
    "    print(f\"ðŸ–¥ï¸ Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nModel troubleshooting:\")\n",
    "    print(\"1. Check if the model repository 'GleghornLab/medsam-vit-b' exists\")\n",
    "    print(\"2. Verify you have access permissions to this repository\")\n",
    "    print(\"3. Ensure your HuggingFace token has the correct permissions\")\n",
    "    print(\"\\n Cannot continue without valid model. Please fix the issue and try again.\")\n",
    "    raise  # Re-raise the error to stop execution\n",
    "\n",
    "print(\"\\n Setup complete! Dataset and model loaded successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# image_dataset = load_dataset(dataset_input, token=True)\n",
    "\n",
    "# print(\"Dataset info:\")\n",
    "# print(f\"Available splits: {list(image_dataset.keys())}\")\n",
    "# print(f\"Number of train images: {len(image_dataset['train'])}\")\n",
    "# print(f\"Features: {image_dataset['train'].features}\")\n",
    "\n",
    "# # Load MedSAM model from Hugging Face\n",
    "# print(\"\\nLoading MedSAM model from Hugging Face...\")\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# # Download model from Hugging Face repository\n",
    "# MedSAM_CKPT_PATH = hf_hub_download(\n",
    "#     repo_id=\"GleghornLab/medsam-vit-b\",\n",
    "#     filename=\"medsam_vit_b.pth\",\n",
    "#     token=True\n",
    "# )\n",
    "\n",
    "# print(f\"Model downloaded to: {MedSAM_CKPT_PATH}\")\n",
    "\n",
    "# # Load the model\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "# medsam_model = medsam_model.to(device)\n",
    "# medsam_model.eval()\n",
    "# print(f\"MedSAM model loaded successfully on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68268013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Pure MedSAM Approach (Closest to Original)\n",
    "import numpy as np\n",
    "\n",
    "class PureMedSAMInterface:\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def load_image(self, image_index):\n",
    "        \"\"\"Load image using pure MedSAM approach\"\"\"\n",
    "        if image_index >= len(self.dataset['train']):\n",
    "            print(f\"Index {image_index} out of range. Max: {len(self.dataset['train'])-1}\")\n",
    "            return\n",
    "            \n",
    "        sample = self.dataset['train'][image_index]\n",
    "        image = sample['image']\n",
    "        \n",
    "        print(f\"Loading Image #{image_index + 1}\")\n",
    "        print(f\"Size: {image.size}\")\n",
    "        \n",
    "        # Convert PIL to numpy (this is the only adaptation needed)\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Use MedSAM EXACTLY as intended - this is the original MedSAM demo\n",
    "        demo = BboxPromptDemo(self.model)\n",
    "        return demo.show(image_array)  # This is the standard MedSAM way\n",
    "        \n",
    "    def preview_images(self, start_idx=0, num_images=9):\n",
    "        \"\"\"Simple preview to help select images\"\"\"\n",
    "        print(f\"Preview: Images {start_idx} to {start_idx + num_images - 1}\")\n",
    "        \n",
    "        fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "        axs = axs.flatten()\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            idx = start_idx + i\n",
    "            if idx < len(self.dataset['train']):\n",
    "                image = self.dataset['train'][idx]['image']\n",
    "                axs[i].imshow(image)\n",
    "                axs[i].set_title(f\"Image #{idx + 1}\")\n",
    "                axs[i].axis('off')\n",
    "            else:\n",
    "                axs[i].axis('off')\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Initialize Native Interface\n",
    "interface = SimpleMedSAMInterface(medsam_model, image_dataset)\n",
    "\n",
    "# Preview images\n",
    "interface.preview_images(0, 9)\n",
    "\n",
    "print(\"\\nNative MedSAM Commands:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"â€¢ interface.load_image(n) - Load image for multi-region segmentation\")\n",
    "print(\"â€¢ interface.preview_images(start, count) - Preview images\")\n",
    "\n",
    "print(\"\\nHow to Use:\")\n",
    "print(\"1. interface.load_image(5)\")\n",
    "print(\"2. Click and drag multiple bounding boxes\")\n",
    "print(\"3. Each box automatically segments\")\n",
    "print(\"4. All regions handled in one interface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce65bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Quick Functions\n",
    "def load_image(n):\n",
    "    return interface.load_image(n)\n",
    "\n",
    "def preview(start=0):\n",
    "    interface.preview_images(start, 9)\n",
    "\n",
    "print(\"Quick Commands:\")\n",
    "print(\"â€¢ load_image(n)\")\n",
    "print(\"â€¢ preview()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bd04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

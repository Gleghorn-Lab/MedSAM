{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 0:\n",
    "!pip install -r requirements.txt -U\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Authentication\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import huggingface_hub\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "from utils.demo import BboxPromptDemo\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "hf_token = input(\"Enter your Hugging Face token: \")\n",
    "huggingface_hub.login(token=hf_token)\n",
    "\n",
    "print(\"Authentication successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cfe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Dataset and Model (From Hugging Face)\n",
    "\n",
    "print(\"Loading lymph node dataset...\")\n",
    "dataset_input = input(\"Please enter dataset path: \")\n",
    "\n",
    "try:\n",
    "    # First, analyze the dataset structure\n",
    "    temp_dataset = load_dataset(dataset_input, token=True)\n",
    "    \n",
    "    print(\"ðŸ” Dataset Analysis:\")\n",
    "    print(f\"Available splits: {list(temp_dataset.keys())}\")\n",
    "    for split_name in temp_dataset.keys():\n",
    "        print(f\"  - {split_name}: {len(temp_dataset[split_name])} items\")\n",
    "        if len(temp_dataset[split_name]) > 0:\n",
    "            print(f\"    Features: {temp_dataset[split_name].features}\")\n",
    "    \n",
    "    # Choose which split to use as 'train'\n",
    "    chosen_split = input(f\"Which split to use as 'train'? {list(temp_dataset.keys())}: \")\n",
    "    \n",
    "    if chosen_split in temp_dataset:\n",
    "        print(f\"Will use '{chosen_split}' split\")\n",
    "        \n",
    "        # Load the chosen split and create 'train' alias\n",
    "        image_dataset = temp_dataset\n",
    "        image_dataset['train'] = image_dataset[chosen_split]\n",
    "        \n",
    "        print(\"Dataset info:\")\n",
    "        print(f\"Available splits: {list(image_dataset.keys())}\")\n",
    "        print(f\"Number of train images: {len(image_dataset['train'])}\")\n",
    "        print(f\"Features: {image_dataset['train'].features}\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\" Split '{chosen_split}' not found in dataset\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"\\n Troubleshooting:\")\n",
    "    print(\"1. Check if the dataset repository exists and is accessible\")\n",
    "    print(\"2. Verify your HuggingFace token has the correct permissions\")\n",
    "    print(\"3. Make sure the dataset path is correct\")\n",
    "    print(\"4. Try a different split name if available\")\n",
    "    print(\"\\n Cannot continue without valid dataset. Please fix the issue and try again.\")\n",
    "    raise  # Re-raise the error to stop execution\n",
    "\n",
    "# Load MedSAM model from Hugging Face\n",
    "print(\"\\nLoading MedSAM model from Hugging Face...\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "try:\n",
    "    # Use your manually downloaded checkpoint if already downloaded\n",
    "    MedSAM_CKPT_PATH = \"/home/medsam-vit-b/medsam_vit_b.pth\"\n",
    "    \n",
    "    # #OR USE THIS section to download the model directly from Hugging Face into cache\n",
    "    # MedSAM_CKPT_PATH = hf_hub_download(\n",
    "    #     repo_id=\"GleghornLab/medsam-vit-b\",\n",
    "    #     filename=\"medsam_vit_b.pth\",\n",
    "    #     token=True\n",
    "    # )\n",
    "    \n",
    "    print(f\"Model downloaded to: {MedSAM_CKPT_PATH}\")\n",
    "    \n",
    "    # Load the model\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "    medsam_model = medsam_model.to(device)\n",
    "    medsam_model.eval()\n",
    "    \n",
    "    print(f\"MedSAM model loaded successfully on {device}\")\n",
    "    \n",
    "    # Show device info\n",
    "    print(f\"ðŸ–¥ï¸ Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nModel troubleshooting:\")\n",
    "    print(\"1. Check if the model repository 'GleghornLab/medsam-vit-b' exists\")\n",
    "    print(\"2. Verify you have access permissions to this repository\")\n",
    "    print(\"3. Ensure your HuggingFace token has the correct permissions\")\n",
    "    print(\"\\n Cannot continue without valid model. Please fix the issue and try again.\")\n",
    "    raise  # Re-raise the error to stop execution\n",
    "\n",
    "print(\"\\n Setup complete! Dataset and model loaded successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# image_dataset = load_dataset(dataset_input, token=True)\n",
    "\n",
    "# print(\"Dataset info:\")\n",
    "# print(f\"Available splits: {list(image_dataset.keys())}\")\n",
    "# print(f\"Number of train images: {len(image_dataset['train'])}\")\n",
    "# print(f\"Features: {image_dataset['train'].features}\")\n",
    "\n",
    "# # Load MedSAM model from Hugging Face\n",
    "# print(\"\\nLoading MedSAM model from Hugging Face...\")\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# # Download model from Hugging Face repository\n",
    "# MedSAM_CKPT_PATH = hf_hub_download(\n",
    "#     repo_id=\"GleghornLab/medsam-vit-b\",\n",
    "#     filename=\"medsam_vit_b.pth\",\n",
    "#     token=True\n",
    "# )\n",
    "\n",
    "# print(f\"Model downloaded to: {MedSAM_CKPT_PATH}\")\n",
    "\n",
    "# # Load the model\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "# medsam_model = medsam_model.to(device)\n",
    "# medsam_model.eval()\n",
    "# print(f\"MedSAM model loaded successfully on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5150d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Compact Optimized MedSAM Interface - Fixed Layout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import LassoSelector, Button, Slider\n",
    "from matplotlib.path import Path\n",
    "import torch\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "class AdjustableViewLassoMedSAMInterface:\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.original_image = None  # Original for MedSAM processing\n",
    "        self.display_image = None   # Adjusted for viewing only\n",
    "        self.lasso_points = []\n",
    "        self.current_mask = None\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        self.current_image_index = None\n",
    "        \n",
    "        # Display adjustment parameters (viewing only)\n",
    "        self.brightness = 1.0\n",
    "        self.contrast = 1.0\n",
    "        self.size_factor = 0.15  # Start small for performance\n",
    "        \n",
    "        # Storage for results\n",
    "        self.segmentation_results = []\n",
    "        \n",
    "    def load_image(self, image_index):\n",
    "        \"\"\"Load an image with viewing adjustments and lasso selection\"\"\"\n",
    "        if image_index >= len(self.dataset['train']):\n",
    "            print(f\"Index {image_index} out of range. Max: {len(self.dataset['train'])-1}\")\n",
    "            return\n",
    "            \n",
    "        self.current_image_index = image_index\n",
    "        sample = self.dataset['train'][image_index]\n",
    "        pil_image = sample['image']\n",
    "        \n",
    "        print(f\"Loading Image #{image_index + 1}\")\n",
    "        print(f\"Original size: {pil_image.size}\")\n",
    "        \n",
    "        # Store original image for MedSAM processing (never modified)\n",
    "        self.original_image = np.array(pil_image)\n",
    "        self.original_pil_image = pil_image\n",
    "        \n",
    "        # Reset to default settings\n",
    "        self.brightness = 1.0\n",
    "        self.contrast = 1.0\n",
    "        self.size_factor = 0.15  # Start at 15% for good visibility\n",
    "        \n",
    "        print(f\"Display starting at {self.size_factor:.1%} size\")\n",
    "        \n",
    "        # Initialize display image\n",
    "        self.update_display_image()\n",
    "        \n",
    "        # Create the interactive interface\n",
    "        self.setup_adjustable_interface()\n",
    "        \n",
    "    def update_display_image(self):\n",
    "        \"\"\"Update display image with viewing adjustments (original unchanged)\"\"\"\n",
    "        adjusted_image = self.original_pil_image.copy()\n",
    "        \n",
    "        # Apply size first (most important for performance)\n",
    "        new_size = tuple(int(dim * self.size_factor) for dim in adjusted_image.size)\n",
    "        # Ensure minimum size for visibility\n",
    "        new_size = tuple(max(200, dim) for dim in new_size)\n",
    "        adjusted_image = adjusted_image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Apply brightness/contrast to smaller image\n",
    "        if self.brightness != 1.0:\n",
    "            enhancer = ImageEnhance.Brightness(adjusted_image)\n",
    "            adjusted_image = enhancer.enhance(self.brightness)\n",
    "        \n",
    "        if self.contrast != 1.0:\n",
    "            enhancer = ImageEnhance.Contrast(adjusted_image)\n",
    "            adjusted_image = enhancer.enhance(self.contrast)\n",
    "        \n",
    "        self.display_image = np.array(adjusted_image)\n",
    "        \n",
    "    def setup_adjustable_interface(self):\n",
    "        \"\"\"Setup compact interface that fits in Jupyter\"\"\"\n",
    "        if self.fig is not None:\n",
    "            plt.close(self.fig)\n",
    "        \n",
    "        # Much smaller figure size to fit in Jupyter\n",
    "        self.fig = plt.figure(figsize=(12, 8))\n",
    "        plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "        \n",
    "        # Main image axes - larger area for image\n",
    "        self.ax_image = plt.axes([0.05, 0.25, 0.6, 0.7])\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        self.ax_image.set_title(f\"Image #{self.current_image_index + 1} - Lasso Tool\\nDisplay: {self.display_image.shape[:2]}\", fontsize=10)\n",
    "        self.ax_image.axis('off')  # Remove axes for cleaner look\n",
    "        \n",
    "        # Simple lasso selector\n",
    "        self.lasso = LassoSelector(self.ax_image, self.on_lasso_select,\n",
    "                                  props=dict(color='red', linewidth=2))\n",
    "        \n",
    "        self.add_compact_controls()\n",
    "        \n",
    "        print(\"âœ… Interface loaded!\")\n",
    "        print(f\"ðŸ“± Display: {self.display_image.shape[:2]} (use sliders to adjust)\")\n",
    "        print(f\"ðŸ”¬ Processing: {self.original_image.shape[:2]} (full resolution)\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def add_compact_controls(self):\n",
    "        \"\"\"Add compact controls on the right side\"\"\"\n",
    "        # Sliders on the right\n",
    "        slider_width = 0.25\n",
    "        slider_height = 0.02\n",
    "        slider_x = 0.7\n",
    "        \n",
    "        # Size slider\n",
    "        ax_size = plt.axes([slider_x, 0.85, slider_width, slider_height])\n",
    "        self.slider_size = Slider(ax_size, 'Size', 0.1, 0.6, valinit=self.size_factor, valfmt='%.2f')\n",
    "        self.slider_size.on_changed(self.update_view_size)\n",
    "        \n",
    "        # Brightness slider\n",
    "        ax_brightness = plt.axes([slider_x, 0.8, slider_width, slider_height])\n",
    "        self.slider_brightness = Slider(ax_brightness, 'Bright', 0.5, 2.0, valinit=1.0, valfmt='%.1f')\n",
    "        self.slider_brightness.on_changed(self.update_view_brightness)\n",
    "        \n",
    "        # Contrast slider\n",
    "        ax_contrast = plt.axes([slider_x, 0.75, slider_width, slider_height])\n",
    "        self.slider_contrast = Slider(ax_contrast, 'Contrast', 0.5, 2.0, valinit=1.0, valfmt='%.1f')\n",
    "        self.slider_contrast.on_changed(self.update_view_contrast)\n",
    "        \n",
    "        # Info display\n",
    "        ax_info = plt.axes([slider_x, 0.7, slider_width, 0.03])\n",
    "        ax_info.text(0.1, 0.5, f\"Current: {self.display_image.shape[1]}x{self.display_image.shape[0]}\", \n",
    "                    transform=ax_info.transAxes, fontsize=8)\n",
    "        ax_info.set_xticks([])\n",
    "        ax_info.set_yticks([])\n",
    "        \n",
    "        # Control buttons - arranged vertically on right\n",
    "        button_width = 0.12\n",
    "        button_height = 0.04\n",
    "        button_x = slider_x + 0.02\n",
    "        \n",
    "        ax_test = plt.axes([button_x, 0.55, button_width, button_height])\n",
    "        ax_accept = plt.axes([button_x, 0.5, button_width, button_height])\n",
    "        ax_clear = plt.axes([button_x, 0.45, button_width, button_height])\n",
    "        ax_new = plt.axes([button_x, 0.4, button_width, button_height])\n",
    "        ax_save = plt.axes([button_x, 0.35, button_width, button_height])\n",
    "        \n",
    "        self.btn_test = Button(ax_test, 'Test Seg')\n",
    "        self.btn_accept = Button(ax_accept, 'Accept')\n",
    "        self.btn_clear = Button(ax_clear, 'Clear')\n",
    "        self.btn_new = Button(ax_new, 'New Region')\n",
    "        self.btn_save = Button(ax_save, 'Save All')\n",
    "        \n",
    "        self.btn_test.on_clicked(self.test_segmentation)\n",
    "        self.btn_accept.on_clicked(self.accept_segmentation)\n",
    "        self.btn_clear.on_clicked(self.clear_selection)\n",
    "        self.btn_new.on_clicked(self.new_region)\n",
    "        self.btn_save.on_clicked(self.save_all_results)\n",
    "        \n",
    "        # Navigation buttons at bottom\n",
    "        nav_y = 0.05\n",
    "        ax_prev = plt.axes([0.05, nav_y, 0.08, 0.04])\n",
    "        ax_next = plt.axes([0.15, nav_y, 0.08, 0.04])\n",
    "        ax_goto = plt.axes([0.25, nav_y, 0.08, 0.04])\n",
    "        \n",
    "        self.btn_prev = Button(ax_prev, 'Previous')\n",
    "        self.btn_next = Button(ax_next, 'Next')\n",
    "        self.btn_goto = Button(ax_goto, 'Go to...')\n",
    "        \n",
    "        self.btn_prev.on_clicked(self.previous_image)\n",
    "        self.btn_next.on_clicked(self.next_image)\n",
    "        self.btn_goto.on_clicked(self.goto_image)\n",
    "        \n",
    "    def update_view_size(self, val):\n",
    "        \"\"\"Update viewing size only\"\"\"\n",
    "        self.size_factor = val\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def update_view_brightness(self, val):\n",
    "        self.brightness = val\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def update_view_contrast(self, val):\n",
    "        self.contrast = val\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def refresh_display(self):\n",
    "        \"\"\"Refresh the display efficiently\"\"\"\n",
    "        self.update_display_image()\n",
    "        self.ax_image.clear()\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        self.ax_image.set_title(f\"Image #{self.current_image_index + 1} - Lasso Tool\\nDisplay: {self.display_image.shape[:2]}\", fontsize=10)\n",
    "        self.ax_image.axis('off')\n",
    "        \n",
    "        # Recreate lasso selector\n",
    "        self.lasso = LassoSelector(self.ax_image, self.on_lasso_select,\n",
    "                                  props=dict(color='red', linewidth=2))\n",
    "        \n",
    "        # Clear selection when view changes\n",
    "        self.lasso_points = []\n",
    "        self.current_mask = None\n",
    "        \n",
    "        self.fig.canvas.draw_idle()\n",
    "        \n",
    "    def on_lasso_select(self, verts):\n",
    "        \"\"\"Handle lasso selection - scale coordinates to original image and keep visible\"\"\"\n",
    "        if len(verts) > 2:\n",
    "            # Scale display coordinates to original image coordinates\n",
    "            scale_factor = 1.0 / self.size_factor\n",
    "            self.lasso_points = [(x * scale_factor, y * scale_factor) for x, y in verts]\n",
    "            \n",
    "            # Keep lasso visible on display\n",
    "            display_lasso = [(x * self.size_factor, y * self.size_factor) for x, y in self.lasso_points]\n",
    "            lasso_array = np.array(display_lasso + [display_lasso[0]])  # Close the loop\n",
    "            \n",
    "            # Draw the lasso outline permanently\n",
    "            if hasattr(self, 'lasso_line'):\n",
    "                self.lasso_line.remove()\n",
    "            \n",
    "            self.lasso_line = self.ax_image.plot(lasso_array[:, 0], lasso_array[:, 1], \n",
    "                                            'r-', linewidth=2, alpha=0.8)[0]\n",
    "            \n",
    "            # Add start/end markers\n",
    "            if hasattr(self, 'lasso_markers'):\n",
    "                self.lasso_markers.remove()\n",
    "            \n",
    "            self.lasso_markers = self.ax_image.plot(display_lasso[0][0], display_lasso[0][1], \n",
    "                                                'ro', markersize=6, alpha=0.8)[0]\n",
    "            \n",
    "            self.fig.canvas.draw_idle()\n",
    "            \n",
    "            print(f\"âœ“ Lasso drawn with {len(verts)} points (staying visible)\")\n",
    "            \n",
    "    def test_segmentation(self, event):\n",
    "        \"\"\"Test segmentation using ORIGINAL full-resolution image\"\"\"\n",
    "        if not self.lasso_points:\n",
    "            print(\"âŒ Please draw a lasso first!\")\n",
    "            return\n",
    "            \n",
    "        print(\"ðŸ”¬ Running MedSAM...\")\n",
    "        \n",
    "        # Convert lasso to bounding box on original coordinates\n",
    "        points = np.array(self.lasso_points)\n",
    "        x_min, y_min = points.min(axis=0).astype(int)\n",
    "        x_max, y_max = points.max(axis=0).astype(int)\n",
    "        \n",
    "        # Ensure bbox is within bounds\n",
    "        x_min = max(0, x_min)\n",
    "        y_min = max(0, y_min)\n",
    "        x_max = min(self.original_image.shape[1], x_max)\n",
    "        y_max = min(self.original_image.shape[0], y_max)\n",
    "        \n",
    "        bbox = np.array([x_min, y_min, x_max, y_max])\n",
    "        print(f\"ðŸ“¦ Bbox: {bbox}\")\n",
    "        \n",
    "        # Get segmentation from MedSAM\n",
    "        self.current_mask = self.get_medsam_segmentation(bbox)\n",
    "        self.current_mask = self.refine_with_lasso(self.current_mask)\n",
    "        \n",
    "        self.show_segmentation_result()\n",
    "        \n",
    "    def get_medsam_segmentation(self, bbox):\n",
    "        \"\"\"Get segmentation from MedSAM using ORIGINAL image\"\"\"\n",
    "        img_tensor = torch.tensor(self.original_image).float()\n",
    "        if len(img_tensor.shape) == 3:\n",
    "            img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        \n",
    "        img_tensor = img_tensor.unsqueeze(0).to(self.model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_embeddings = self.model.image_encoder(img_tensor)\n",
    "            bbox_tensor = torch.tensor(bbox).float().unsqueeze(0).to(self.model.device)\n",
    "            \n",
    "            sparse_embeddings, dense_embeddings = self.model.prompt_encoder(\n",
    "                points=None, boxes=bbox_tensor, masks=None,\n",
    "            )\n",
    "            \n",
    "            masks, iou_predictions = self.model.mask_decoder(\n",
    "                image_embeddings=image_embeddings,\n",
    "                image_pe=self.model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparse_embeddings,\n",
    "                dense_prompt_embeddings=dense_embeddings,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "            \n",
    "            mask = masks[0, 0].cpu().numpy()\n",
    "            \n",
    "        print(\"âœ… Segmentation complete!\")\n",
    "        return mask > 0.5\n",
    "        \n",
    "    def refine_with_lasso(self, mask):\n",
    "        \"\"\"Refine mask using lasso path on original coordinates\"\"\"\n",
    "        if not self.lasso_points:\n",
    "            return mask\n",
    "            \n",
    "        path = Path(self.lasso_points)\n",
    "        h, w = mask.shape\n",
    "        y, x = np.mgrid[:h, :w]\n",
    "        points = np.column_stack((x.ravel(), y.ravel()))\n",
    "        inside_lasso = path.contains_points(points).reshape(h, w)\n",
    "        return mask & inside_lasso\n",
    "        \n",
    "    def show_segmentation_result(self):\n",
    "        \"\"\"Display segmentation result scaled to display\"\"\"\n",
    "        if self.current_mask is None:\n",
    "            return\n",
    "            \n",
    "        # Scale mask to display size\n",
    "        mask_pil = Image.fromarray((self.current_mask * 255).astype(np.uint8))\n",
    "        display_size = self.display_image.shape[:2][::-1]\n",
    "        scaled_mask_pil = mask_pil.resize(display_size, Image.Resampling.NEAREST)\n",
    "        display_mask = np.array(scaled_mask_pil) > 127\n",
    "            \n",
    "        # Show result\n",
    "        self.ax_image.clear()\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        \n",
    "        # Overlay mask\n",
    "        masked = np.ma.masked_where(~display_mask, display_mask)\n",
    "        self.ax_image.imshow(masked, alpha=0.6, cmap='Reds')\n",
    "        \n",
    "        # Show lasso outline\n",
    "        if self.lasso_points:\n",
    "            display_lasso = [(x * self.size_factor, y * self.size_factor) for x, y in self.lasso_points]\n",
    "            lasso_array = np.array(display_lasso)\n",
    "            self.ax_image.plot(lasso_array[:, 0], lasso_array[:, 1], 'r-', linewidth=2)\n",
    "            \n",
    "        self.ax_image.set_title(f\"âœ… Segmentation Result - Image #{self.current_image_index + 1}\", fontsize=10)\n",
    "        self.ax_image.axis('off')\n",
    "        self.fig.canvas.draw_idle()\n",
    "        \n",
    "    def accept_segmentation(self, event):\n",
    "        \"\"\"Accept and save the current segmentation\"\"\"\n",
    "        if self.current_mask is None:\n",
    "            print(\"âŒ No segmentation to accept!\")\n",
    "            return\n",
    "        \n",
    "        # Store result\n",
    "        result = {\n",
    "            'image_index': self.current_image_index,\n",
    "            'mask': self.current_mask.copy(),\n",
    "            'lasso_points': self.lasso_points.copy(),\n",
    "            'bbox': self.get_bbox_from_lasso(),\n",
    "            'mask_pixels': int(np.sum(self.current_mask)),\n",
    "            'settings': {\n",
    "                'brightness': self.brightness,\n",
    "                'contrast': self.contrast,\n",
    "                'size_factor': self.size_factor\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.segmentation_results.append(result)\n",
    "        \n",
    "        print(\"âœ… Segmentation accepted!\")\n",
    "        print(f\"ðŸ“Š Pixels: {np.sum(self.current_mask)}\")\n",
    "        print(f\"ðŸ’¾ Total saved: {len(self.segmentation_results)}\")\n",
    "        self.new_region(event)\n",
    "        \n",
    "    def get_bbox_from_lasso(self):\n",
    "        \"\"\"Get bounding box from lasso points\"\"\"\n",
    "        if not self.lasso_points:\n",
    "            return None\n",
    "        points = np.array(self.lasso_points)\n",
    "        x_min, y_min = points.min(axis=0).astype(int)\n",
    "        x_max, y_max = points.max(axis=0).astype(int)\n",
    "        return [x_min, y_min, x_max, y_max]\n",
    "        \n",
    "    def clear_selection(self, event):\n",
    "        \"\"\"Clear the current selection\"\"\"\n",
    "        self.lasso_points = []\n",
    "        self.current_mask = None\n",
    "        \n",
    "        # Remove persistent lasso lines if they exist\n",
    "        if hasattr(self, 'lasso_line'):\n",
    "            self.lasso_line.remove()\n",
    "            delattr(self, 'lasso_line')\n",
    "        \n",
    "        if hasattr(self, 'lasso_markers'):\n",
    "            self.lasso_markers.remove()\n",
    "            delattr(self, 'lasso_markers')\n",
    "        \n",
    "        self.ax_image.clear()\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        self.ax_image.set_title(f\"Image #{self.current_image_index + 1} - Lasso Tool\\nDisplay: {self.display_image.shape[:2]}\", fontsize=10)\n",
    "        self.ax_image.axis('off')\n",
    "        \n",
    "        self.lasso = LassoSelector(self.ax_image, self.on_lasso_select,\n",
    "                                props=dict(color='red', linewidth=2))\n",
    "        self.fig.canvas.draw_idle()\n",
    "        print(\"ðŸ§¹ Selection cleared\")\n",
    "        \n",
    "    def new_region(self, event):\n",
    "        \"\"\"Start selecting a new region\"\"\"\n",
    "        self.lasso_points = []\n",
    "        self.lasso = LassoSelector(self.ax_image, self.on_lasso_select,\n",
    "                                  props=dict(color='blue', linewidth=2))\n",
    "        self.ax_image.set_title(f\"ðŸ†• Draw another region - Image #{self.current_image_index + 1}\", fontsize=10)\n",
    "        print(\"ðŸŽ¯ Ready for new region\")\n",
    "        \n",
    "    def previous_image(self, event):\n",
    "        \"\"\"Load previous image\"\"\"\n",
    "        if self.current_image_index > 0:\n",
    "            self.load_image(self.current_image_index - 1)\n",
    "        else:\n",
    "            print(\"Already at first image\")\n",
    "            \n",
    "    def next_image(self, event):\n",
    "        \"\"\"Load next image\"\"\"\n",
    "        if self.current_image_index < len(self.dataset['train']) - 1:\n",
    "            self.load_image(self.current_image_index + 1)\n",
    "        else:\n",
    "            print(\"Already at last image\")\n",
    "            \n",
    "    def goto_image(self, event):\n",
    "        \"\"\"Go to specific image\"\"\"\n",
    "        try:\n",
    "            idx = int(input(f\"Enter image index (0-{len(self.dataset['train'])-1}): \"))\n",
    "            self.load_image(idx)\n",
    "        except:\n",
    "            print(\"Invalid index\")\n",
    "            \n",
    "    def save_all_results(self, event):\n",
    "        \"\"\"Save all segmentation results\"\"\"\n",
    "        if not self.segmentation_results:\n",
    "            print(\"âŒ No results to save!\")\n",
    "            return\n",
    "            \n",
    "        import os\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # Create output directory\n",
    "        output_dir = \"lymph_node_segmentations\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save results as numpy archive\n",
    "        masks = [r['mask'] for r in self.segmentation_results]\n",
    "        metadata = {i: {k: v for k, v in r.items() if k != 'mask'} \n",
    "                   for i, r in enumerate(self.segmentation_results)}\n",
    "        \n",
    "        filename = os.path.join(output_dir, f\"segmentations_{timestamp}.npz\")\n",
    "        np.savez_compressed(filename, masks=masks, metadata=metadata)\n",
    "        \n",
    "        print(f\"ðŸ’¾ Saved {len(self.segmentation_results)} segmentations to {filename}\")\n",
    "        \n",
    "    def preview_images(self, start_idx=0, num_images=9):\n",
    "        \"\"\"Preview images at reduced resolution\"\"\"\n",
    "        print(f\"ðŸ–¼ï¸ Preview: Images {start_idx} to {start_idx + num_images - 1}\")\n",
    "        \n",
    "        fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "        axs = axs.flatten()\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            idx = start_idx + i\n",
    "            if idx < len(self.dataset['train']):\n",
    "                image = self.dataset['train'][idx]['image']\n",
    "                # Show at reduced size for preview\n",
    "                if max(image.size) > 300:\n",
    "                    preview_size = tuple(int(dim * 300 / max(image.size)) for dim in image.size)\n",
    "                    image = image.resize(preview_size, Image.Resampling.LANCZOS)\n",
    "                \n",
    "                axs[i].imshow(image)\n",
    "                axs[i].set_title(f\"#{idx + 1}\")\n",
    "                axs[i].axis('off')\n",
    "            else:\n",
    "                axs[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Initialize Adjustable View Interface\n",
    "interface = AdjustableViewLassoMedSAMInterface(medsam_model, image_dataset)\n",
    "\n",
    "# Preview images\n",
    "interface.preview_images(0, 9)\n",
    "\n",
    "print(\"\\nAdjustable View Lasso MedSAM Commands:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"â€¢ interface.load_image(n) - Load image with viewing adjustments\")\n",
    "print(\"â€¢ interface.preview_images(start, count) - Preview images\")\n",
    "\n",
    "print(\"\\nKey Features:\")\n",
    "print(\"âœ“ Viewing adjustments: size, brightness, contrast (temporary)\")\n",
    "print(\"âœ“ MedSAM processing: always uses original unmodified image\")\n",
    "print(\"âœ“ Coordinate mapping: lasso coordinates mapped to original image\")\n",
    "print(\"âœ“ Visual feedback: see adjustments while maintaining data integrity\")\n",
    "\n",
    "print(\"\\nHow to Use:\")\n",
    "print(\"1. interface.load_image(5)\")\n",
    "print(\"2. Adjust viewing parameters as needed\")\n",
    "print(\"3. Draw a lasso around your region\")\n",
    "print(\"4. Click 'Test Segmentation' (processes original image)\")\n",
    "print(\"5. Click 'Accept' or 'Clear' to continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce65bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Quick Functions\n",
    "def load_image(n):\n",
    "    return interface.load_image(n)\n",
    "\n",
    "def preview(start=0):\n",
    "    interface.preview_images(start, 9)\n",
    "\n",
    "print(\"Quick Commands:\")\n",
    "print(\"â€¢ load_image(n)\")\n",
    "print(\"â€¢ preview()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 6\n",
    "load_image(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

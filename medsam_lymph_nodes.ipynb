{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 0:\n",
    "!pip install -r requirements.txt -U\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Authentication\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import huggingface_hub\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "from utils.demo import BboxPromptDemo\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "hf_token = input(\"Enter your Hugging Face token: \")\n",
    "huggingface_hub.login(token=hf_token)\n",
    "\n",
    "print(\"Authentication successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cfe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Dataset and Model (From Hugging Face)\n",
    "\n",
    "print(\"Loading lymph node dataset...\")\n",
    "dataset_input = input(\"Please enter dataset path: \")\n",
    "\n",
    "try:\n",
    "    # First, analyze the dataset structure\n",
    "    temp_dataset = load_dataset(dataset_input, token=True)\n",
    "    \n",
    "    print(\"🔍 Dataset Analysis:\")\n",
    "    print(f\"Available splits: {list(temp_dataset.keys())}\")\n",
    "    for split_name in temp_dataset.keys():\n",
    "        print(f\"  - {split_name}: {len(temp_dataset[split_name])} items\")\n",
    "        if len(temp_dataset[split_name]) > 0:\n",
    "            print(f\"    Features: {temp_dataset[split_name].features}\")\n",
    "    \n",
    "    # Choose which split to use as 'train'\n",
    "    chosen_split = input(f\"Which split to use as 'train'? {list(temp_dataset.keys())}: \")\n",
    "    \n",
    "    if chosen_split in temp_dataset:\n",
    "        print(f\"Will use '{chosen_split}' split\")\n",
    "        \n",
    "        # Load the chosen split and create 'train' alias\n",
    "        image_dataset = temp_dataset\n",
    "        image_dataset['train'] = image_dataset[chosen_split]\n",
    "        \n",
    "        print(\"Dataset info:\")\n",
    "        print(f\"Available splits: {list(image_dataset.keys())}\")\n",
    "        print(f\"Number of train images: {len(image_dataset['train'])}\")\n",
    "        print(f\"Features: {image_dataset['train'].features}\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\" Split '{chosen_split}' not found in dataset\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"\\n Troubleshooting:\")\n",
    "    print(\"1. Check if the dataset repository exists and is accessible\")\n",
    "    print(\"2. Verify your HuggingFace token has the correct permissions\")\n",
    "    print(\"3. Make sure the dataset path is correct\")\n",
    "    print(\"4. Try a different split name if available\")\n",
    "    print(\"\\n Cannot continue without valid dataset. Please fix the issue and try again.\")\n",
    "    raise  # Re-raise the error to stop execution\n",
    "\n",
    "# Load MedSAM model from Hugging Face\n",
    "print(\"\\nLoading MedSAM model from Hugging Face...\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "try:\n",
    "    # Use your manually downloaded checkpoint if already downloaded\n",
    "    MedSAM_CKPT_PATH = \"/home/medsam-vit-b/medsam_vit_b.pth\"\n",
    "    \n",
    "    # #OR USE THIS section to download the model directly from Hugging Face into cache\n",
    "    # MedSAM_CKPT_PATH = hf_hub_download(\n",
    "    #     repo_id=\"GleghornLab/medsam-vit-b\",\n",
    "    #     filename=\"medsam_vit_b.pth\",\n",
    "    #     token=True\n",
    "    # )\n",
    "    \n",
    "    print(f\"Model downloaded to: {MedSAM_CKPT_PATH}\")\n",
    "    \n",
    "    # Load the model\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "    medsam_model = medsam_model.to(device)\n",
    "    medsam_model.eval()\n",
    "    \n",
    "    print(f\"MedSAM model loaded successfully on {device}\")\n",
    "    \n",
    "    # Show device info\n",
    "    print(f\"🖥️ Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nModel troubleshooting:\")\n",
    "    print(\"1. Check if the model repository 'GleghornLab/medsam-vit-b' exists\")\n",
    "    print(\"2. Verify you have access permissions to this repository\")\n",
    "    print(\"3. Ensure your HuggingFace token has the correct permissions\")\n",
    "    print(\"\\n Cannot continue without valid model. Please fix the issue and try again.\")\n",
    "    raise  # Re-raise the error to stop execution\n",
    "\n",
    "print(\"\\n Setup complete! Dataset and model loaded successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# image_dataset = load_dataset(dataset_input, token=True)\n",
    "\n",
    "# print(\"Dataset info:\")\n",
    "# print(f\"Available splits: {list(image_dataset.keys())}\")\n",
    "# print(f\"Number of train images: {len(image_dataset['train'])}\")\n",
    "# print(f\"Features: {image_dataset['train'].features}\")\n",
    "\n",
    "# # Load MedSAM model from Hugging Face\n",
    "# print(\"\\nLoading MedSAM model from Hugging Face...\")\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# # Download model from Hugging Face repository\n",
    "# MedSAM_CKPT_PATH = hf_hub_download(\n",
    "#     repo_id=\"GleghornLab/medsam-vit-b\",\n",
    "#     filename=\"medsam_vit_b.pth\",\n",
    "#     token=True\n",
    "# )\n",
    "\n",
    "# print(f\"Model downloaded to: {MedSAM_CKPT_PATH}\")\n",
    "\n",
    "# # Load the model\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "# medsam_model = medsam_model.to(device)\n",
    "# medsam_model.eval()\n",
    "# print(f\"MedSAM model loaded successfully on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5150d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced MedSAM Interface with Viewing Adjustments and Lasso Selection\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import LassoSelector, Button, Slider\n",
    "from matplotlib.path import Path\n",
    "import torch\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "class AdjustableViewLassoMedSAMInterface:\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.original_image = None  # Original for MedSAM processing\n",
    "        self.display_image = None   # Adjusted for viewing only\n",
    "        self.lasso_points = []\n",
    "        self.current_mask = None\n",
    "        self.fig = None\n",
    "        self.ax_image = None\n",
    "        \n",
    "        # Display adjustment parameters (viewing only)\n",
    "        self.brightness = 1.0\n",
    "        self.contrast = 1.0\n",
    "        self.size_factor = 1.0\n",
    "        \n",
    "    def load_image(self, image_index):\n",
    "        \"\"\"Load an image with viewing adjustments and lasso selection\"\"\"\n",
    "        if image_index >= len(self.dataset['train']):\n",
    "            print(f\"Index {image_index} out of range. Max: {len(self.dataset['train'])-1}\")\n",
    "            return\n",
    "            \n",
    "        sample = self.dataset['train'][image_index]\n",
    "        pil_image = sample['image']\n",
    "        \n",
    "        print(f\"Loading Image #{image_index + 1}\")\n",
    "        print(f\"Original size: {pil_image.size}\")\n",
    "        \n",
    "        # Store original image for MedSAM processing (never modified)\n",
    "        self.original_image = np.array(pil_image)\n",
    "        self.original_pil_image = pil_image\n",
    "        \n",
    "        # Reset viewing adjustment parameters\n",
    "        self.brightness = 1.0\n",
    "        self.contrast = 1.0\n",
    "        self.size_factor = 1.0\n",
    "        \n",
    "        # Initialize display image\n",
    "        self.update_display_image()\n",
    "        \n",
    "        # Create the interactive interface\n",
    "        self.setup_adjustable_interface()\n",
    "        \n",
    "    def update_display_image(self):\n",
    "        \"\"\"Update display image with viewing adjustments (original unchanged)\"\"\"\n",
    "        # Start with original PIL image for adjustments\n",
    "        adjusted_image = self.original_pil_image.copy()\n",
    "        \n",
    "        # Apply viewing adjustments\n",
    "        if self.size_factor != 1.0:\n",
    "            new_size = tuple(int(dim * self.size_factor) for dim in adjusted_image.size)\n",
    "            adjusted_image = adjusted_image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        if self.brightness != 1.0:\n",
    "            enhancer = ImageEnhance.Brightness(adjusted_image)\n",
    "            adjusted_image = enhancer.enhance(self.brightness)\n",
    "        \n",
    "        if self.contrast != 1.0:\n",
    "            enhancer = ImageEnhance.Contrast(adjusted_image)\n",
    "            adjusted_image = enhancer.enhance(self.contrast)\n",
    "        \n",
    "        # Convert to numpy for display\n",
    "        self.display_image = np.array(adjusted_image)\n",
    "        \n",
    "    def setup_adjustable_interface(self):\n",
    "        \"\"\"Setup the interface with viewing adjustments and lasso selection\"\"\"\n",
    "        # Close any existing figure\n",
    "        if self.fig is not None:\n",
    "            plt.close(self.fig)\n",
    "        \n",
    "        # Create figure with subplots for controls\n",
    "        self.fig = plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Main image axes\n",
    "        self.ax_image = plt.axes([0.1, 0.3, 0.6, 0.6])\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        self.ax_image.set_title(\"Draw a lasso around the region (adjustments are for viewing only)\")\n",
    "        \n",
    "        # Create lasso selector\n",
    "        self.lasso = LassoSelector(\n",
    "            self.ax_image, \n",
    "            self.on_lasso_select,\n",
    "            useblit=True,\n",
    "            lineprops={'color': 'red', 'linewidth': 2}\n",
    "        )\n",
    "        \n",
    "        # Add adjustment sliders\n",
    "        self.add_viewing_sliders()\n",
    "        \n",
    "        # Add control buttons\n",
    "        self.add_control_buttons()\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"Adjustable View Lasso MedSAM Interface:\")\n",
    "        print(\"• Viewing adjustments: size, brightness, contrast (temporary)\")\n",
    "        print(\"• MedSAM processing uses original unmodified image\")\n",
    "        print(\"• Draw lasso, test segmentation, accept or clear\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def add_viewing_sliders(self):\n",
    "        \"\"\"Add sliders for viewing adjustments only\"\"\"\n",
    "        # Size slider\n",
    "        ax_size = plt.axes([0.75, 0.8, 0.15, 0.03])\n",
    "        self.slider_size = Slider(ax_size, 'View Size', 0.5, 2.0, valinit=1.0, valfmt='%.1f')\n",
    "        self.slider_size.on_changed(self.update_view_size)\n",
    "        \n",
    "        # Brightness slider\n",
    "        ax_brightness = plt.axes([0.75, 0.75, 0.15, 0.03])\n",
    "        self.slider_brightness = Slider(ax_brightness, 'View Brightness', 0.5, 2.0, valinit=1.0, valfmt='%.1f')\n",
    "        self.slider_brightness.on_changed(self.update_view_brightness)\n",
    "        \n",
    "        # Contrast slider\n",
    "        ax_contrast = plt.axes([0.75, 0.7, 0.15, 0.03])\n",
    "        self.slider_contrast = Slider(ax_contrast, 'View Contrast', 0.5, 2.0, valinit=1.0, valfmt='%.1f')\n",
    "        self.slider_contrast.on_changed(self.update_view_contrast)\n",
    "        \n",
    "        # Reset viewing button\n",
    "        ax_reset = plt.axes([0.75, 0.65, 0.08, 0.04])\n",
    "        self.btn_reset = Button(ax_reset, 'Reset View')\n",
    "        self.btn_reset.on_clicked(self.reset_view_adjustments)\n",
    "        \n",
    "    def add_control_buttons(self):\n",
    "        \"\"\"Add control buttons\"\"\"\n",
    "        ax_test = plt.axes([0.1, 0.15, 0.12, 0.04])\n",
    "        ax_accept = plt.axes([0.23, 0.15, 0.12, 0.04])\n",
    "        ax_clear = plt.axes([0.36, 0.15, 0.12, 0.04])\n",
    "        ax_new_region = plt.axes([0.49, 0.15, 0.12, 0.04])\n",
    "        \n",
    "        self.btn_test = Button(ax_test, 'Test Segmentation')\n",
    "        self.btn_accept = Button(ax_accept, 'Accept')\n",
    "        self.btn_clear = Button(ax_clear, 'Clear')\n",
    "        self.btn_new = Button(ax_new_region, 'New Region')\n",
    "        \n",
    "        self.btn_test.on_clicked(self.test_segmentation)\n",
    "        self.btn_accept.on_clicked(self.accept_segmentation)\n",
    "        self.btn_clear.on_clicked(self.clear_selection)\n",
    "        self.btn_new.on_clicked(self.new_region)\n",
    "        \n",
    "    def update_view_size(self, val):\n",
    "        \"\"\"Update viewing size only\"\"\"\n",
    "        self.size_factor = val\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def update_view_brightness(self, val):\n",
    "        \"\"\"Update viewing brightness only\"\"\"\n",
    "        self.brightness = val\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def update_view_contrast(self, val):\n",
    "        \"\"\"Update viewing contrast only\"\"\"\n",
    "        self.contrast = val\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def reset_view_adjustments(self, event):\n",
    "        \"\"\"Reset viewing adjustments to default\"\"\"\n",
    "        self.slider_size.reset()\n",
    "        self.slider_brightness.reset()\n",
    "        self.slider_contrast.reset()\n",
    "        self.size_factor = 1.0\n",
    "        self.brightness = 1.0\n",
    "        self.contrast = 1.0\n",
    "        self.refresh_display()\n",
    "        \n",
    "    def refresh_display(self):\n",
    "        \"\"\"Refresh the display with current viewing adjustments\"\"\"\n",
    "        self.update_display_image()\n",
    "        self.ax_image.clear()\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        self.ax_image.set_title(\"Draw a lasso around the region (adjustments are for viewing only)\")\n",
    "        \n",
    "        # Recreate lasso selector\n",
    "        self.lasso = LassoSelector(\n",
    "            self.ax_image, \n",
    "            self.on_lasso_select,\n",
    "            useblit=True,\n",
    "            lineprops={'color': 'red', 'linewidth': 2}\n",
    "        )\n",
    "        \n",
    "        # Clear lasso points when display changes\n",
    "        self.lasso_points = []\n",
    "        self.current_mask = None\n",
    "        \n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "    def on_lasso_select(self, verts):\n",
    "        \"\"\"Handle lasso selection\"\"\"\n",
    "        if len(verts) > 2:\n",
    "            # Convert display coordinates to original image coordinates\n",
    "            if self.size_factor != 1.0:\n",
    "                # Scale lasso points back to original image size\n",
    "                self.lasso_points = [(x/self.size_factor, y/self.size_factor) for x, y in verts]\n",
    "            else:\n",
    "                self.lasso_points = verts\n",
    "            print(f\"Lasso drawn with {len(verts)} points (mapped to original image coordinates)\")\n",
    "            \n",
    "    def test_segmentation(self, event):\n",
    "        \"\"\"Test segmentation using ORIGINAL image, not adjusted display\"\"\"\n",
    "        if not self.lasso_points:\n",
    "            print(\"Please draw a lasso first!\")\n",
    "            return\n",
    "            \n",
    "        print(\"Testing segmentation on ORIGINAL image...\")\n",
    "        \n",
    "        # Convert lasso to bounding box using original image coordinates\n",
    "        points = np.array(self.lasso_points)\n",
    "        x_min, y_min = points.min(axis=0).astype(int)\n",
    "        x_max, y_max = points.max(axis=0).astype(int)\n",
    "        \n",
    "        # Ensure bbox is within original image bounds\n",
    "        x_min = max(0, x_min)\n",
    "        y_min = max(0, y_min)\n",
    "        x_max = min(self.original_image.shape[1], x_max)\n",
    "        y_max = min(self.original_image.shape[0], y_max)\n",
    "        \n",
    "        bbox = np.array([x_min, y_min, x_max, y_max])\n",
    "        print(f\"Using bounding box on original image: {bbox}\")\n",
    "        \n",
    "        # Get segmentation from MedSAM using ORIGINAL image\n",
    "        self.current_mask = self.get_medsam_segmentation(bbox)\n",
    "        \n",
    "        # Refine mask using lasso path on original coordinates\n",
    "        self.current_mask = self.refine_with_lasso(self.current_mask)\n",
    "        \n",
    "        # Display result\n",
    "        self.show_segmentation_result()\n",
    "        \n",
    "    def get_medsam_segmentation(self, bbox):\n",
    "        \"\"\"Get segmentation from MedSAM using ORIGINAL image\"\"\"\n",
    "        # Use ORIGINAL image for MedSAM processing\n",
    "        img_tensor = torch.tensor(self.original_image).float()\n",
    "        if len(img_tensor.shape) == 3:\n",
    "            img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        \n",
    "        img_tensor = img_tensor.unsqueeze(0).to(self.model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_embeddings = self.model.image_encoder(img_tensor)\n",
    "            bbox_tensor = torch.tensor(bbox).float().unsqueeze(0).to(self.model.device)\n",
    "            \n",
    "            sparse_embeddings, dense_embeddings = self.model.prompt_encoder(\n",
    "                points=None, boxes=bbox_tensor, masks=None,\n",
    "            )\n",
    "            \n",
    "            masks, iou_predictions = self.model.mask_decoder(\n",
    "                image_embeddings=image_embeddings,\n",
    "                image_pe=self.model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparse_embeddings,\n",
    "                dense_prompt_embeddings=dense_embeddings,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "            \n",
    "            mask = masks[0, 0].cpu().numpy()\n",
    "            \n",
    "        return mask > 0.5\n",
    "        \n",
    "    def refine_with_lasso(self, mask):\n",
    "        \"\"\"Refine mask using lasso path on original image coordinates\"\"\"\n",
    "        if not self.lasso_points:\n",
    "            return mask\n",
    "            \n",
    "        path = Path(self.lasso_points)\n",
    "        h, w = mask.shape\n",
    "        y, x = np.mgrid[:h, :w]\n",
    "        points = np.column_stack((x.ravel(), y.ravel()))\n",
    "        inside_lasso = path.contains_points(points).reshape(h, w)\n",
    "        refined_mask = mask & inside_lasso\n",
    "        \n",
    "        return refined_mask\n",
    "        \n",
    "    def show_segmentation_result(self):\n",
    "        \"\"\"Display segmentation result scaled to match display\"\"\"\n",
    "        if self.current_mask is None:\n",
    "            return\n",
    "            \n",
    "        # Scale mask to match display if needed\n",
    "        if self.size_factor != 1.0:\n",
    "            mask_pil = Image.fromarray((self.current_mask * 255).astype(np.uint8))\n",
    "            display_size = self.display_image.shape[:2][::-1]  # PIL uses (width, height)\n",
    "            scaled_mask_pil = mask_pil.resize(display_size, Image.Resampling.NEAREST)\n",
    "            display_mask = np.array(scaled_mask_pil) > 127\n",
    "        else:\n",
    "            display_mask = self.current_mask\n",
    "            \n",
    "        # Clear and redraw with current display adjustments\n",
    "        self.ax_image.clear()\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        \n",
    "        # Overlay scaled mask\n",
    "        masked = np.ma.masked_where(~display_mask, display_mask)\n",
    "        self.ax_image.imshow(masked, alpha=0.6, cmap='Reds')\n",
    "        \n",
    "        # Draw lasso outline on display coordinates\n",
    "        if self.lasso_points:\n",
    "            if self.size_factor != 1.0:\n",
    "                display_lasso = [(x*self.size_factor, y*self.size_factor) for x, y in self.lasso_points]\n",
    "            else:\n",
    "                display_lasso = self.lasso_points\n",
    "            lasso_array = np.array(display_lasso)\n",
    "            self.ax_image.plot(lasso_array[:, 0], lasso_array[:, 1], 'r-', linewidth=2)\n",
    "            \n",
    "        self.ax_image.set_title(\"Segmentation Result (processed on original image)\")\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "    def accept_segmentation(self, event):\n",
    "        \"\"\"Accept the current segmentation\"\"\"\n",
    "        if self.current_mask is None:\n",
    "            print(\"No segmentation to accept!\")\n",
    "            return\n",
    "            \n",
    "        print(\"Segmentation accepted!\")\n",
    "        print(f\"Mask shape: {self.current_mask.shape} (from original image)\")\n",
    "        print(f\"Segmented pixels: {np.sum(self.current_mask)}\")\n",
    "        self.new_region(event)\n",
    "        \n",
    "    def clear_selection(self, event):\n",
    "        \"\"\"Clear the current selection\"\"\"\n",
    "        self.lasso_points = []\n",
    "        self.current_mask = None\n",
    "        \n",
    "        self.ax_image.clear()\n",
    "        self.ax_image.imshow(self.display_image)\n",
    "        self.ax_image.set_title(\"Draw a lasso around the region (adjustments are for viewing only)\")\n",
    "        \n",
    "        self.lasso = LassoSelector(\n",
    "            self.ax_image, self.on_lasso_select,\n",
    "            useblit=True, lineprops={'color': 'red', 'linewidth': 2}\n",
    "        )\n",
    "        \n",
    "        self.fig.canvas.draw()\n",
    "        print(\"Selection cleared\")\n",
    "        \n",
    "    def new_region(self, event):\n",
    "        \"\"\"Start selecting a new region\"\"\"\n",
    "        self.lasso_points = []\n",
    "        \n",
    "        self.lasso = LassoSelector(\n",
    "            self.ax_image, self.on_lasso_select,\n",
    "            useblit=True, lineprops={'color': 'blue', 'linewidth': 2}\n",
    "        )\n",
    "        \n",
    "        self.ax_image.set_title(\"Draw another region (previous shown in red)\")\n",
    "        print(\"Ready for new region selection\")\n",
    "        \n",
    "    def preview_images(self, start_idx=0, num_images=9):\n",
    "        \"\"\"Preview images\"\"\"\n",
    "        print(f\"Preview: Images {start_idx} to {start_idx + num_images - 1}\")\n",
    "        \n",
    "        fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "        axs = axs.flatten()\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            idx = start_idx + i\n",
    "            if idx < len(self.dataset['train']):\n",
    "                image = self.dataset['train'][idx]['image']\n",
    "                axs[i].imshow(image)\n",
    "                axs[i].set_title(f\"Image #{idx + 1}\")\n",
    "                axs[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68268013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Initialize Lasso Interface\n",
    "interface = LassoMedSAMInterface(medsam_model, image_dataset)\n",
    "\n",
    "# Preview images\n",
    "interface.preview_images(0, 9)\n",
    "\n",
    "print(\"\\nLasso MedSAM Commands:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• interface.load_image(n) - Load image with lasso interface\")\n",
    "print(\"• interface.preview_images(start, count) - Preview images\")\n",
    "\n",
    "print(\"\\nHow to Use:\")\n",
    "print(\"1. interface.load_image(5)\")\n",
    "print(\"2. Draw a lasso around your region\")\n",
    "print(\"3. Click 'Test Segmentation' to see result\")\n",
    "print(\"4. Click 'Accept' or 'Clear' to continue\")\n",
    "print(\"5. Click 'New Region' for multiple regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Initialize Adjustable View Interface\n",
    "interface = AdjustableViewLassoMedSAMInterface(medsam_model, image_dataset)\n",
    "\n",
    "# Preview images\n",
    "interface.preview_images(0, 9)\n",
    "\n",
    "print(\"\\nAdjustable View Lasso MedSAM Commands:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"• interface.load_image(n) - Load image with viewing adjustments\")\n",
    "print(\"• interface.preview_images(start, count) - Preview images\")\n",
    "\n",
    "print(\"\\nKey Features:\")\n",
    "print(\"✓ Viewing adjustments: size, brightness, contrast (temporary)\")\n",
    "print(\"✓ MedSAM processing: always uses original unmodified image\")\n",
    "print(\"✓ Coordinate mapping: lasso coordinates mapped to original image\")\n",
    "print(\"✓ Visual feedback: see adjustments while maintaining data integrity\")\n",
    "\n",
    "print(\"\\nHow to Use:\")\n",
    "print(\"1. interface.load_image(5)\")\n",
    "print(\"2. Adjust viewing parameters as needed\")\n",
    "print(\"3. Draw a lasso around your region\")\n",
    "print(\"4. Click 'Test Segmentation' (processes original image)\")\n",
    "print(\"5. Click 'Accept' or 'Clear' to continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce65bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Quick Functions\n",
    "def load_image(n):\n",
    "    return interface.load_image(n)\n",
    "\n",
    "def preview(start=0):\n",
    "    interface.preview_images(start, 9)\n",
    "\n",
    "print(\"Quick Commands:\")\n",
    "print(\"• load_image(n)\")\n",
    "print(\"• preview()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_image(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
